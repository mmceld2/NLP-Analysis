{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk import pos_tag\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/judge-1377884607_tweet_product_company.csv',encoding='latin1')\n",
    "df.rename(columns = {'emotion_in_tweet_is_directed_at': 'Product', 'is_there_an_emotion_directed_at_a_brand_or_product': 'Emotion', 'tweet_text': 'Tweet'}, inplace= True)\n",
    "df.drop(9092, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet_tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or buffer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d7cea68cc61c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtweet_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Tweet\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtweet_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/nltk/tokenize/casual.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \"\"\"\n\u001b[1;32m    285\u001b[0m         \u001b[0;31m# Fix HTML character entities:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_replace_html_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;31m# Remove username handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip_handles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/nltk/tokenize/casual.py\u001b[0m in \u001b[0;36m_replace_html_entities\u001b[0;34m(text, keep, remove_illegal, encoding)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mremove_illegal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mENT_RE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_entity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_str_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or buffer"
     ]
    }
   ],
   "source": [
    "tweet_tokens = []\n",
    "for tweet in df[\"Tweet\"]:\n",
    "    tweet_tokens.append(tweet_tokenizer.tokenize(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/judge-1377884607_tweet_product_company.csv',encoding='latin1')\n",
    "df.rename(columns = {'emotion_in_tweet_is_directed_at': 'Product', 'is_there_an_emotion_directed_at_a_brand_or_product': 'Emotion', 'tweet_text': 'Tweet'}, inplace= True)\n",
    "df.drop(9092, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df['Text'] = df['Tweet'].str.lower()\n",
    "df['Text'] = df['Text'].str.replace(r'[^\\w\\s]', '')\n",
    "df['Text'] = df['Text'].str.split(' ')\n",
    "df.dropna(subset=['Text'], inplace=True)\n",
    "df['test'] = ''\n",
    "df.fillna('na', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_keywords = ['apple', '#apple', 'ipad', '#ipad', '#iphone', 'iphone', 'itunes', '#itunes', 'ios', 'airpods', '#ios', '#airpods'\n",
    "                 'iphones', 'ipads', 'apples', 'quotapple', 'quotipad', 'ipadquot', 'quotipads', 'ipadsquot', 'applequot', 'quotiphone', 'iphonequot', 'quotios', 'iosquot', 'quotiphones', 'iphonesquot', 'ipad2']\n",
    "google_keywords = ['google', '#google', 'android', '#android', 'googles', 'androids', 'quotgoogle', 'googlequot', 'quotandroid', 'androidquot', 'quotandroids', 'androidsquot' ]\n",
    "\n",
    "for ind, val in enumerate(df['Text']):\n",
    "    if df['Product'].values[ind] == 'na':\n",
    "        for y in val:\n",
    "            if y in apple_keywords:\n",
    "                df['test'].values[ind] = y\n",
    "            elif y in google_keywords:\n",
    "                df['test'].values[ind] = y\n",
    "                \n",
    "    else:\n",
    "        df['test'].values[ind] = df['Product'].values[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['test'] = df['test'].map(lambda x: x.lower())\n",
    "df['test'] = df['test'].replace({'googles': 'google', 'apples': 'apple', 'androids': 'android','ipads': 'ipad', 'ipad2': 'ipad',\n",
    "                                'quotgoogle': 'google', 'ipadquot': 'ipad', 'quotipad': 'ipad', 'androidquot': 'android', 'applequot': 'apple',\n",
    "                               'googlequot': 'google', 'iphonequot': 'iphone', 'quotapple' : 'apple', 'iosquot': 'ios', 'quotiphone': 'iphone',\n",
    "                                '#ipad' : 'ipad', '#google' : 'google', '#android': 'android', '#apple': 'apple', '#iphone': 'iphone'})\n",
    "emotion_dict = {'No emotion toward brand or product' : 'Neutral emotion', \"I can't tell\": 'Neutral emotion', 'Positive emotion': 'Positive emotion',\n",
    "               'Negative emotion': 'Negative emotion'}\n",
    "df['Emotion'] = df['Emotion'].map(emotion_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def company_search(test):\n",
    "    if test == 'iphone':\n",
    "        return 'apple'\n",
    "    elif test == 'apple':\n",
    "        return 'apple'\n",
    "    elif test == 'ipad':\n",
    "        return 'apple'\n",
    "    elif test == 'ipad or iphone app':\n",
    "        return 'apple'\n",
    "    elif test == 'itunes':\n",
    "        return 'apple'\n",
    "    elif test == 'other apple product or service':\n",
    "        return 'apple'\n",
    "    elif test == 'ios':\n",
    "        return 'apple'\n",
    "    elif test == 'ipadquot':\n",
    "        return 'apple'\n",
    "    elif test == 'applequot':\n",
    "        return 'apple'\n",
    "    elif test == 'iphonequot':\n",
    "        return 'apple'\n",
    "    elif test == 'quotiphone':\n",
    "        return 'apple'\n",
    "    elif test == 'iosquot':\n",
    "        return 'apple'\n",
    "    elif test =='quotipad':\n",
    "        return 'apple'\n",
    "    elif test == 'quotapple':\n",
    "        return 'apple'\n",
    "    elif test =='google':\n",
    "        return 'google'\n",
    "    elif test == 'android':\n",
    "        return 'google'\n",
    "    elif test == 'other google product or service':\n",
    "        return 'google'\n",
    "    elif test == 'android app':\n",
    "        return 'google'\n",
    "    elif test == 'quotgoogle':\n",
    "        return 'google'\n",
    "    elif test == 'googlequot':\n",
    "        return 'google'\n",
    "    elif test == 'androidquot':\n",
    "        return 'google'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "    \n",
    "df['company'] = df['test'].apply(company_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dict = {'Negative emotion': 0, 'Neutral emotion': 1, 'Positive emotion': 2}\n",
    "df['target'] = df['Emotion'].map(target_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "sw = stopwords.words('english')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = ['sxsw', 'mention', 'link', 'ipad', 'iphone', 'google', 'apple', '2', 'android', 'rt']\n",
    "sw.extend(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
