{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk import pos_tag\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, plot_confusion_matrix, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/judge-1377884607_tweet_product_company.csv',encoding='latin1')\n",
    "df.rename(columns = {'emotion_in_tweet_is_directed_at': 'Product', 'is_there_an_emotion_directed_at_a_brand_or_product': 'Emotion', 'tweet_text': 'Tweet'}, inplace= True)\n",
    "df.drop(9092, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet_tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/judge-1377884607_tweet_product_company.csv',encoding='latin1')\n",
    "df.rename(columns = {'emotion_in_tweet_is_directed_at': 'Product', 'is_there_an_emotion_directed_at_a_brand_or_product': 'Emotion', 'tweet_text': 'Tweet'}, inplace= True)\n",
    "df.drop(9092, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df['Text'] = df['Tweet'].str.lower()\n",
    "df['Text'] = df['Text'].str.replace(r'[^\\w\\s]', '')\n",
    "df['Text'] = df['Text'].str.split(' ')\n",
    "df.dropna(subset=['Text'], inplace=True)\n",
    "df['test'] = ''\n",
    "df.fillna('na', inplace=True)\n",
    "df.reset_index(drop= True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_keywords = ['apple', '#apple', 'ipad', '#ipad', '#iphone', 'iphone', 'itunes', '#itunes', 'ios', 'airpods', '#ios', '#airpods'\n",
    "                 'iphones', 'ipads', 'apples', 'quotapple', 'quotipad', 'ipadquot', 'quotipads', 'ipadsquot', 'applequot', 'quotiphone', 'iphonequot', 'quotios', 'iosquot', 'quotiphones', 'iphonesquot', 'ipad2']\n",
    "google_keywords = ['google', '#google', 'android', '#android', 'googles', 'androids', 'quotgoogle', 'googlequot', 'quotandroid', 'androidquot', 'quotandroids', 'androidsquot' ]\n",
    "\n",
    "for ind, val in enumerate(df['Text']):\n",
    "    if df['Product'].values[ind] == 'na':\n",
    "        for y in val:\n",
    "            if y in apple_keywords:\n",
    "                df['test'].values[ind] = y\n",
    "            elif y in google_keywords:\n",
    "                df['test'].values[ind] = y\n",
    "                \n",
    "    else:\n",
    "        df['test'].values[ind] = df['Product'].values[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['test'] = df['test'].map(lambda x: x.lower())\n",
    "df['test'] = df['test'].replace({'googles': 'google', 'apples': 'apple', 'androids': 'android','ipads': 'ipad', 'ipad2': 'ipad',\n",
    "                                'quotgoogle': 'google', 'ipadquot': 'ipad', 'quotipad': 'ipad', 'androidquot': 'android', 'applequot': 'apple',\n",
    "                               'googlequot': 'google', 'iphonequot': 'iphone', 'quotapple' : 'apple', 'iosquot': 'ios', 'quotiphone': 'iphone',\n",
    "                                '#ipad' : 'ipad', '#google' : 'google', '#android': 'android', '#apple': 'apple', '#iphone': 'iphone'})\n",
    "emotion_dict = {'No emotion toward brand or product' : 'Neutral emotion', \"I can't tell\": 'Neutral emotion', 'Positive emotion': 'Positive emotion',\n",
    "               'Negative emotion': 'Negative emotion'}\n",
    "df['Emotion'] = df['Emotion'].map(emotion_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def company_search(test):\n",
    "    if test == 'iphone':\n",
    "        return 'apple'\n",
    "    elif test == 'apple':\n",
    "        return 'apple'\n",
    "    elif test == 'ipad':\n",
    "        return 'apple'\n",
    "    elif test == 'ipad or iphone app':\n",
    "        return 'apple'\n",
    "    elif test == 'itunes':\n",
    "        return 'apple'\n",
    "    elif test == 'other apple product or service':\n",
    "        return 'apple'\n",
    "    elif test == 'ios':\n",
    "        return 'apple'\n",
    "    elif test == 'ipadquot':\n",
    "        return 'apple'\n",
    "    elif test == 'applequot':\n",
    "        return 'apple'\n",
    "    elif test == 'iphonequot':\n",
    "        return 'apple'\n",
    "    elif test == 'quotiphone':\n",
    "        return 'apple'\n",
    "    elif test == 'iosquot':\n",
    "        return 'apple'\n",
    "    elif test =='quotipad':\n",
    "        return 'apple'\n",
    "    elif test == 'quotapple':\n",
    "        return 'apple'\n",
    "    elif test =='google':\n",
    "        return 'google'\n",
    "    elif test == 'android':\n",
    "        return 'google'\n",
    "    elif test == 'other google product or service':\n",
    "        return 'google'\n",
    "    elif test == 'android app':\n",
    "        return 'google'\n",
    "    elif test == 'quotgoogle':\n",
    "        return 'google'\n",
    "    elif test == 'googlequot':\n",
    "        return 'google'\n",
    "    elif test == 'androidquot':\n",
    "        return 'google'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "    \n",
    "df['company'] = df['test'].apply(company_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dict = {'Negative emotion': 0, 'Neutral emotion': 1, 'Positive emotion': 2}\n",
    "df['target'] = df['Emotion'].map(target_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "sw = stopwords.words('english')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = ['sxsw', 'mention', 'link', 'ipad', 'iphone', 'google', 'apple', '2', 'android', 'rt']\n",
    "sw2 = sw.extend(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['neg_target'] = df['target'].map({0:1, 1:0, 2:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Product</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "      <th>test</th>\n",
       "      <th>company</th>\n",
       "      <th>target</th>\n",
       "      <th>neg_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[wesley83, i, have, a, 3g, iphone, after, 3, h...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>apple</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[jessedee, know, about, fludapp, , awesome, ip...</td>\n",
       "      <td>ipad or iphone app</td>\n",
       "      <td>apple</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[swonderlin, can, not, wait, for, ipad, 2, als...</td>\n",
       "      <td>ipad</td>\n",
       "      <td>apple</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[sxsw, i, hope, this, years, festival, isnt, a...</td>\n",
       "      <td>ipad or iphone app</td>\n",
       "      <td>apple</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[sxtxstate, great, stuff, on, fri, sxsw, maris...</td>\n",
       "      <td>google</td>\n",
       "      <td>google</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9086</th>\n",
       "      <td>@mention Yup, but I don't have a third app yet...</td>\n",
       "      <td>na</td>\n",
       "      <td>Neutral emotion</td>\n",
       "      <td>[mention, yup, but, i, dont, have, a, third, a...</td>\n",
       "      <td>android</td>\n",
       "      <td>google</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9087</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[ipad, everywhere, sxsw, link]</td>\n",
       "      <td>ipad</td>\n",
       "      <td>apple</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>na</td>\n",
       "      <td>Neutral emotion</td>\n",
       "      <td>[wave, buzz, rt, mention, we, interrupt, your,...</td>\n",
       "      <td>google</td>\n",
       "      <td>google</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>na</td>\n",
       "      <td>Neutral emotion</td>\n",
       "      <td>[googles, zeiger, a, physician, never, reporte...</td>\n",
       "      <td>google</td>\n",
       "      <td>google</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>na</td>\n",
       "      <td>Neutral emotion</td>\n",
       "      <td>[some, verizon, iphone, customers, complained,...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>apple</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9091 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet             Product  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3     @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "...                                                 ...                 ...   \n",
       "9086  @mention Yup, but I don't have a third app yet...                  na   \n",
       "9087                      Ipad everywhere. #SXSW {link}                iPad   \n",
       "9088  Wave, buzz... RT @mention We interrupt your re...                  na   \n",
       "9089  Google's Zeiger, a physician never reported po...                  na   \n",
       "9090  Some Verizon iPhone customers complained their...                  na   \n",
       "\n",
       "               Emotion                                               Text  \\\n",
       "0     Negative emotion  [wesley83, i, have, a, 3g, iphone, after, 3, h...   \n",
       "1     Positive emotion  [jessedee, know, about, fludapp, , awesome, ip...   \n",
       "2     Positive emotion  [swonderlin, can, not, wait, for, ipad, 2, als...   \n",
       "3     Negative emotion  [sxsw, i, hope, this, years, festival, isnt, a...   \n",
       "4     Positive emotion  [sxtxstate, great, stuff, on, fri, sxsw, maris...   \n",
       "...                ...                                                ...   \n",
       "9086   Neutral emotion  [mention, yup, but, i, dont, have, a, third, a...   \n",
       "9087  Positive emotion                     [ipad, everywhere, sxsw, link]   \n",
       "9088   Neutral emotion  [wave, buzz, rt, mention, we, interrupt, your,...   \n",
       "9089   Neutral emotion  [googles, zeiger, a, physician, never, reporte...   \n",
       "9090   Neutral emotion  [some, verizon, iphone, customers, complained,...   \n",
       "\n",
       "                    test company  target  neg_target  \n",
       "0                 iphone   apple       0           1  \n",
       "1     ipad or iphone app   apple       2           0  \n",
       "2                   ipad   apple       2           0  \n",
       "3     ipad or iphone app   apple       0           1  \n",
       "4                 google  google       2           0  \n",
       "...                  ...     ...     ...         ...  \n",
       "9086             android  google       1           0  \n",
       "9087                ipad   apple       2           0  \n",
       "9088              google  google       1           0  \n",
       "9089              google  google       1           0  \n",
       "9090              iphone   apple       1           0  \n",
       "\n",
       "[9091 rows x 8 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline as imbpipe\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.Text.str.join(' ')\n",
    "y = df.neg_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfpipe = imbpipe(steps = [\n",
    "    ('tfidf', TfidfVectorizer(max_features =1000, stop_words=sw, ngram_range = (1, 2))),\n",
    "    ('sm', SMOTE()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnbpipe = Pipeline(steps = [\n",
    "    ('tfidf', TfidfVectorizer(max_features =500, stop_words=sw, ngram_range = (1, 2))),\n",
    "    ('sm', SMOTE(sampling_strategy = .8)),\n",
    "    ('mnb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_recall = make_scorer(recall_score, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cross_validate(rfpipe, X_train, y_train, scoring = macro_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train = cross_val_predict(mnbpipe, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5420,  971],\n",
       "       [ 215,  212]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_hat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat1 = cross_val_predict(mnbpipe, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7099, 1422],\n",
       "       [ 292,  278]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, y_hat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
