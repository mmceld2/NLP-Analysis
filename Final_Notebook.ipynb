{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding\n",
    "from keras import regularizers\n",
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Sequential\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence\n",
    "import matplotlib.pyplot as plt\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer, RegexpTokenizer, TweetTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import pos_tag\n",
    "import seaborn as sns\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression , SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split , cross_validate , GridSearchCV, cross_val_predict\n",
    "from sklearn.pipeline import make_pipeline , Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, recall_score, f1_score, plot_confusion_matrix\n",
    "from nltk.corpus import stopwords as sw\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.tokenize import  word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "pd.set_option ('display.max_colwidth', None)\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbpipe\n",
    "from xgboost import XGBClassifier\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_scores(results):\n",
    "    '''Return Train/Test Mean Score from a Cross Val'''\n",
    "    return print(f'''Mean Train Score: {results['train_score'].mean()}\n",
    "Mean Test Score: {results['test_score'].mean()}''')\n",
    "\n",
    "def metrics(y_true,y_preds):\n",
    "    '''Gives recall,precision,accuracy,F1 score and confusion matrix'''\n",
    "    return print(f'''Recall Score: {recall_score(y_true,y_preds,average='micro')}\n",
    "Precision Score: {precision_score(y_true,y_preds,average='micro')}\n",
    "Accuracy Score:{accuracy_score(y_true,y_preds)}\n",
    "F1 Score: {f1_score(y_true,y_preds,average='micro')}\n",
    "Confusion Matrix: \n",
    "{confusion_matrix(y_true,y_preds)}''')\n",
    "\n",
    "def gs_mean_scores(results):\n",
    "    '''Return Train and Test Scores from a grid search'''\n",
    "    return print(f'''Mean Train Score: {results.cv_results_['mean_train_score'].mean()}'\n",
    "Mean Test Score: {results.cv_results_['mean_test_score'].mean()}''')\n",
    "\n",
    "def company_search(test):\n",
    "    if test == 'iphone':\n",
    "        return 'apple'\n",
    "    elif test == 'apple':\n",
    "        return 'apple'\n",
    "    elif test == 'ipad':\n",
    "        return 'apple'\n",
    "    elif test == 'ipad or iphone app':\n",
    "        return 'apple'\n",
    "    elif test == 'itunes':\n",
    "        return 'apple'\n",
    "    elif test == 'other apple product or service':\n",
    "        return 'apple'\n",
    "    elif test == 'ios':\n",
    "        return 'apple'\n",
    "    elif test == 'ipadquot':\n",
    "        return 'apple'\n",
    "    elif test == 'applequot':\n",
    "        return 'apple'\n",
    "    elif test == 'iphonequot':\n",
    "        return 'apple'\n",
    "    elif test == 'quotiphone':\n",
    "        return 'apple'\n",
    "    elif test == 'iosquot':\n",
    "        return 'apple'\n",
    "    elif test =='quotipad':\n",
    "        return 'apple'\n",
    "    elif test == 'quotapple':\n",
    "        return 'apple'\n",
    "    elif test =='google':\n",
    "        return 'google'\n",
    "    elif test == 'android':\n",
    "        return 'google'\n",
    "    elif test == 'other google product or service':\n",
    "        return 'google'\n",
    "    elif test == 'android app':\n",
    "        return 'google'\n",
    "    elif test == 'quotgoogle':\n",
    "        return 'google'\n",
    "    elif test == 'googlequot':\n",
    "        return 'google'\n",
    "    elif test == 'androidquot':\n",
    "        return 'google'\n",
    "    else:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text                                               1\n",
       "emotion_in_tweet_is_directed_at                       5802\n",
       "is_there_an_emotion_directed_at_a_brand_or_product       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/judge-1377884607_tweet_product_company.csv',encoding='latin1')\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5802 missing values telling what the tweet is directed at. A way to combat this would be to look at the tweet and look for keywords such as iphone or ipad and assign who it is directed to that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We drop the 1 NA value from our dataset\n",
    "df = df.dropna(subset=['tweet_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take out puncuation and other unnecessary characters\n",
    "df['tweet_text'] = df['tweet_text'].str.replace(r'[^\\w\\s]', '')\n",
    "df['tweet_text'] = df['tweet_text'].str.replace('quot', '')\n",
    "# Make lower case and split\n",
    "df['tweet_text'] = df['tweet_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "snbstem = SnowballStemmer('english')\n",
    "df['lem_text'] = df['tweet_text'].apply(lambda x: [snbstem.stem(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_text'] = df['tweet_text'].str.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do some basic cleaning of the data set, removing puncuation making everything lower case and splitting the data. We also use snowball stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a blank column to set up for some data cleaning\n",
    "df['test'] = ''\n",
    "# Fill in the values with a string na to avoid errors\n",
    "df.fillna('na',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This salvages alot of our data\n",
    "\n",
    "apple = ['iphone','ipad','apple','apples','ipads']\n",
    "android = ['android','google','androids','googles']\n",
    "\n",
    "# Loop through the tweet column and look for keywords to assign product to\n",
    "for ind , val in enumerate(df['tweet_text']):\n",
    "    if df['emotion_in_tweet_is_directed_at'].values[ind] == 'na':\n",
    "        for y in val:\n",
    "            if y in apple:\n",
    "                df['test'].values[ind] = y\n",
    "            elif y in android:\n",
    "                df['test'].values[ind] = y\n",
    "                \n",
    "    else:\n",
    "        df['test'].values[ind] = df['emotion_in_tweet_is_directed_at'].values[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this process, we looped over the tweets themselves to see if we could determine what product or company the tweet was above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "915"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[df['test'] == ''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We managed to fill in 4886 rows of missing data with our for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['iphone', 'ipad or iphone app', 'ipad', 'google', 'android',\n",
       "       'apple', 'android app', 'other google product or service', '',\n",
       "       'googles', 'ipads', 'apples', 'other apple product or service',\n",
       "       'androids'], dtype=object)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make everything lower case to make values match\n",
    "df['test'] = df['test'].map(lambda x : x.lower())\n",
    "df['test'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell replaces words with the rightful product to reduce unique values\n",
    "df['test'] = df['test'].replace({'googles': 'google', 'apples': 'apple', 'androids': 'android','ipads':'ipad'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative emotion', 'Positive emotion',\n",
       "       'No emotion toward brand or product', \"I can't tell\"], dtype=object)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_there_an_emotion_directed_at_a_brand_or_product'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the target of our dataset, there seems to be four different values. Negative emotion, positive emotion, no emotion and I can't tell. Let's get a closer look at these 'I can't tell' labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[df['is_there_an_emotion_directed_at_a_brand_or_product'] == \"I can't tell\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this makes up such a small amount of our data, we will move the I can't tell value to that of neutral, along with the value 'No emotion toward brand or product'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we make change targets into more readable text\n",
    "emotion_dict = {'No emotion toward brand or product' : 'Neutral emotion', \"I can't tell\": 'Neutral emotion', 'Positive emotion': 'Positive emotion',\n",
    "               'Negative emotion': 'Negative emotion'}\n",
    "df['is_there_an_emotion_directed_at_a_brand_or_product'] = df['is_there_an_emotion_directed_at_a_brand_or_product'].map(emotion_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative emotion', 'Positive emotion', 'Neutral emotion'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_there_an_emotion_directed_at_a_brand_or_product'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now turned our dataset into a ternary classification set. With this we will now begin our modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_dist = df.groupby('is_there_an_emotion_directed_at_a_brand_or_product').count()\n",
    "fig ,ax = plt.subplots()\n",
    "df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts(normalize=True).plot.bar()\n",
    "\n",
    "plt.xticks(rotation=0,fontsize=10)\n",
    "ax.set_xlabel('Sentiment of Tweet',fontsize=12)\n",
    "ax.set_ylabel('Percent of Distribution',fontsize=12)\n",
    "ax.set_title('Distribution of Sentiments',fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map out our values to prepare for modeling\n",
    "target_dict = {'Negative emotion': 2, 'Neutral emotion': 1, 'Positive emotion': 0}\n",
    "df_test = df.copy()\n",
    "df_test['target'] = df['is_there_an_emotion_directed_at_a_brand_or_product'].map(target_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test['lem_text'].str.join(' ')\n",
    "y = df_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Our test and train set\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our first model we will try a CountVectorizer with Naive Bayes\n",
    "cv = CountVectorizer()\n",
    "\n",
    "X_t_vec = cv.fit_transform(X_train)\n",
    "X_t_vec = cv.fit_transform(X_train)\n",
    "X_t_vec = pd.DataFrame.sparse.from_spmatrix(X_t_vec)\n",
    "X_t_vec.columns = sorted(cv.vocabulary_)\n",
    "X_t_vec.set_index(y_train.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.fit(X_t_vec,y_train)\n",
    "results = cross_validate(mnb,X_t_vec,y_train,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Score: 0.8341765135163467\n",
      "Mean Test Score: 0.6630004754907128\n"
     ]
    }
   ],
   "source": [
    "mean_scores(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our first look at the model, it seems to be overfit. It has high variance from our test and train scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.6630004399472064\n",
      "Precision Score: 0.6630004399472064\n",
      "Accuracy Score:0.6630004399472064\n",
      "F1 Score: 0.6630004399472064\n",
      "Confusion Matrix: \n",
      "[[1274  989   10]\n",
      " [ 854 3199   55]\n",
      " [ 170  220   48]]\n"
     ]
    }
   ],
   "source": [
    "y_hat = cross_val_predict(mnb,X_t_vec,y_train)\n",
    "metrics(y_train,y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model doesn't do a great job at predicting negative sentiments. Let's look at other models to see what we can find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Score: 0.8971621786894103\n",
      "Mean Test Score: 0.6918886878392713\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr_pipe = Pipeline([(\"vec\" , CountVectorizer(stop_words=sw.words('english'))),\n",
    "                       (\"lr\",LogisticRegression(C=.5,solver='saga'))])\n",
    "results_LR = cross_validate(lr_pipe,X_train,y_train,return_train_score=True)\n",
    "mean_scores(results_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scores better than our first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.6917436574277753\n",
      "Precision Score: 0.6917436574277753\n",
      "Accuracy Score:0.6917436574277753\n",
      "F1 Score: 0.6917436574277753\n",
      "Confusion Matrix: \n",
      "[[1157 1097   19]\n",
      " [ 593 3461   54]\n",
      " [  93  246   99]]\n"
     ]
    }
   ],
   "source": [
    "y_hat_lr = cross_val_predict(lr_pipe, X_train, y_train)\n",
    "metrics(y_train,y_hat_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model seems to do a better job at predictin the negative sentiment, but lost some positive snentiments. This is a better model than our first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we try a TFIDFVectorizer with MNB\n",
    "pipe_tf = make_pipeline(TfidfVectorizer(stop_words=sw.words('english')), MultinomialNB())\n",
    "cv = cross_validate(pipe, X_train, y_train,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Score: 0.9961138050323763\n",
      "Mean Test Score: 0.676491394909022\n"
     ]
    }
   ],
   "source": [
    "mean_scores(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our worst model yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.649068778413257\n",
      "Precision Score: 0.649068778413257\n",
      "Accuracy Score:0.649068778413257\n",
      "F1 Score: 0.649068778413257\n",
      "Confusion Matrix: \n",
      "[[ 490 1783    0]\n",
      " [ 172 3935    1]\n",
      " [  44  393    1]]\n"
     ]
    }
   ],
   "source": [
    "y_hat_tf = cross_val_predict(pipe_tf, X_train, y_train)\n",
    "metrics(y_train,y_hat_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model cannot predict any negatives at all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Score: 0.996150468643742\n",
      "Mean Test Score: 0.6773713754590852\n"
     ]
    }
   ],
   "source": [
    "pipe_rf = make_pipeline(TfidfVectorizer(stop_words=sw.words('english')), RandomForestClassifier())\n",
    "cv = cross_validate(pipe_rf, X_train, y_train,return_train_score=True)\n",
    "mean_scores(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.6776653468250476\n",
      "Precision Score: 0.6776653468250476\n",
      "Accuracy Score:0.6776653468250476\n",
      "F1 Score: 0.6776653468250476\n",
      "Confusion Matrix: \n",
      "[[ 898 1372    3]\n",
      " [ 423 3651   34]\n",
      " [  66  300   72]]\n"
     ]
    }
   ],
   "source": [
    "y_hat_rf = cross_val_predict(pipe_rf, X_train, y_train)\n",
    "metrics(y_train,y_hat_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing too special about this model, it is not the highest scoring and does a decent job of classifying negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Score: 0.8246809943257416\n",
      "Mean Test Score: 0.6847026461811211\n"
     ]
    }
   ],
   "source": [
    "lr_pipe = Pipeline([(\"tfid\" , TfidfVectorizer(stop_words='english')),\n",
    "                       (\"lr\",LogisticRegression())])\n",
    "results_LR = cross_validate(lr_pipe,X_train,y_train,return_train_score=True)\n",
    "mean_scores(results_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.6847045021264115\n",
      "Precision Score: 0.6847045021264115\n",
      "Accuracy Score:0.6847045021264115\n",
      "F1 Score: 0.6847045021264115\n",
      "Confusion Matrix: \n",
      "[[1046 1223    4]\n",
      " [ 502 3595   11]\n",
      " [  99  311   28]]\n"
     ]
    }
   ],
   "source": [
    "y_hat_lr = cross_val_predict(lr_pipe,X_train,y_train)\n",
    "metrics(y_train,y_hat_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Althought this does give a good accuracy score, the negative classifying isn't quire there. This model does the best overall at accuracy though. Let's tune some hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid = {'lr__C' : [.5, 1, 50],\n",
    "       'lr__max_iter' : [50,100,1750, 2000],\n",
    "       }\n",
    "\n",
    "clf_lr = GridSearchCV(lr_pipe,lr_grid,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Score: 0.8506531971350055'\n",
      "Mean Test Score: 0.6773342613649812\n"
     ]
    }
   ],
   "source": [
    "lr_results = clf_lr.fit(X_train,y_train)\n",
    "gs_mean_scores(lr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr__C': 1, 'lr__max_iter': 100}"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Score: 0.8246809943257416\n",
      "Mean Test Score: 0.6847026461811211\n"
     ]
    }
   ],
   "source": [
    "lr_pipe2 = Pipeline([(\"tfid\" , TfidfVectorizer(stop_words='english')),\n",
    "                       (\"lr\",LogisticRegression(max_iter=50))])\n",
    "results_LR = cross_validate(lr_pipe,X_train,y_train,return_train_score=True)\n",
    "mean_scores(results_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.6835313095761842\n",
      "Precision Score: 0.6835313095761842\n",
      "Accuracy Score:0.6835313095761842\n",
      "F1 Score: 0.6835313095761842\n",
      "Confusion Matrix: \n",
      "[[1042 1227    4]\n",
      " [ 502 3593   13]\n",
      " [  98  314   26]]\n"
     ]
    }
   ],
   "source": [
    "y_preds = cross_val_predict(lr_pipe2,X_train,y_train)\n",
    "metrics(y_train,y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performs well but is still struggling with the negative classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Score: 0.9137336740755474\n",
      "Mean Test Score: 0.6932087662414503\n"
     ]
    }
   ],
   "source": [
    "svc_pipe = Pipeline([(\"tfid\" , TfidfVectorizer(stop_words=sw.words('english'))),\n",
    "                     (\"svc\", SVC())])\n",
    "results_svc = cross_validate(svc_pipe,X_train,y_train,return_train_score=True)\n",
    "mean_scores(results_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.6932101481155595\n",
      "Precision Score: 0.6932101481155595\n",
      "Accuracy Score:0.6932101481155595\n",
      "F1 Score: 0.6932101481155595\n",
      "Confusion Matrix: \n",
      "[[ 885 1340    1]\n",
      " [ 363 3806   10]\n",
      " [  47  331   36]]\n"
     ]
    }
   ],
   "source": [
    "y_svc = cross_val_predict(svc_pipe,X_train,y_train)\n",
    "metrics(y_train,y_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nn = df_test['target']\n",
    "x_nn = df_test['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = Sequential()\n",
    "model_nn.add(Embedding(7000, 100))\n",
    "model_nn.add(LSTM(25))\n",
    "model_nn.add(Dense(50, activation='relu'))\n",
    "model_nn.add(Dense(3, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_t = text.Tokenizer(num_words=7000)\n",
    "text_t.fit_on_texts((x_nn))\n",
    "list_tt = text_t.texts_to_sequences(x_nn)\n",
    "x_nn = sequence.pad_sequences(list_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, None, 100)         700000    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 25)                12600     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 50)                1300      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 714,053\n",
      "Trainable params: 714,053\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_nn.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7227 - accuracy: 0.3781\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7254 - accuracy: 0.4706\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7263 - accuracy: 0.5365\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7067 - accuracy: 0.4480\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.6903 - accuracy: 0.3299\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7320 - accuracy: 0.3303\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7292 - accuracy: 0.3894\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7408 - accuracy: 0.4655\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7318 - accuracy: 0.5223\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7424 - accuracy: 0.5494\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.6230 - accuracy: 0.5797\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.6990 - accuracy: 0.6157\n",
      "Epoch 13/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7317 - accuracy: 0.6734\n",
      "Epoch 14/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7524 - accuracy: 0.5679\n",
      "Epoch 15/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7666 - accuracy: 0.6011\n",
      "Epoch 16/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7726 - accuracy: 0.6389\n",
      "Epoch 17/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7742 - accuracy: 0.6281\n",
      "Epoch 18/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7653 - accuracy: 0.6980\n",
      "Epoch 19/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7388 - accuracy: 0.6795\n",
      "Epoch 20/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.6623 - accuracy: 0.7256\n",
      "Epoch 21/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7140 - accuracy: 0.6335\n",
      "Epoch 22/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7552 - accuracy: 0.5936\n",
      "Epoch 23/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7647 - accuracy: 0.5881\n",
      "Epoch 24/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7691 - accuracy: 0.6222\n",
      "Epoch 25/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7729 - accuracy: 0.6312\n",
      "Epoch 26/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7792 - accuracy: 0.6819\n",
      "Epoch 27/100\n",
      "285/285 [==============================] - ETA: 0s - loss: -0.7773 - accuracy: 0.730 - 2s 8ms/step - loss: -0.7792 - accuracy: 0.7311\n",
      "Epoch 28/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7796 - accuracy: 0.7003\n",
      "Epoch 29/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7721 - accuracy: 0.7301\n",
      "Epoch 30/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7190 - accuracy: 0.6337\n",
      "Epoch 31/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7241 - accuracy: 0.4822\n",
      "Epoch 32/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7477 - accuracy: 0.4968\n",
      "Epoch 33/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7461 - accuracy: 0.4548\n",
      "Epoch 34/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7779 - accuracy: 0.4786\n",
      "Epoch 35/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7843 - accuracy: 0.5546\n",
      "Epoch 36/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7870 - accuracy: 0.6200\n",
      "Epoch 37/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7889 - accuracy: 0.6075\n",
      "Epoch 38/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7718 - accuracy: 0.6117\n",
      "Epoch 39/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7121 - accuracy: 0.7066\n",
      "Epoch 40/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7098 - accuracy: 0.8328\n",
      "Epoch 41/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7623 - accuracy: 0.8112\n",
      "Epoch 42/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7844 - accuracy: 0.8249\n",
      "Epoch 43/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7892 - accuracy: 0.8374\n",
      "Epoch 44/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7906 - accuracy: 0.8307\n",
      "Epoch 45/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7923 - accuracy: 0.8230\n",
      "Epoch 46/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7921 - accuracy: 0.8293\n",
      "Epoch 47/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7930 - accuracy: 0.8229\n",
      "Epoch 48/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7824 - accuracy: 0.8269\n",
      "Epoch 49/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.6740 - accuracy: 0.8363\n",
      "Epoch 50/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7402 - accuracy: 0.8429\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7755 - accuracy: 0.8525\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7849 - accuracy: 0.8938\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7895 - accuracy: 0.8775\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7361 - accuracy: 0.8029\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.8011 - accuracy: 0.8357\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.8018 - accuracy: 0.8075\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7295 - accuracy: 0.7293\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7658 - accuracy: 0.7371\n",
      "Epoch 59/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7846 - accuracy: 0.4073\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7986 - accuracy: 0.3910\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.8025 - accuracy: 0.3821\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.8004 - accuracy: 0.3891\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.8058 - accuracy: 0.3902\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.8044 - accuracy: 0.3899\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7652 - accuracy: 0.3649\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7854 - accuracy: 0.4810\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7730 - accuracy: 0.5453\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.6765 - accuracy: 0.7077\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7844 - accuracy: 0.7939\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7756 - accuracy: 0.7818\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7914 - accuracy: 0.7731\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7973 - accuracy: 0.8216\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.8038 - accuracy: 0.7865\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.8015 - accuracy: 0.8209\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7880 - accuracy: 0.7887\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7911 - accuracy: 0.8087\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7867 - accuracy: 0.8461\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.8058 - accuracy: 0.8657\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.8165 - accuracy: 0.8721\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.8127 - accuracy: 0.8304\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.8176 - accuracy: 0.8264\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.8020 - accuracy: 0.8158\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7785 - accuracy: 0.8407\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7957 - accuracy: 0.8610\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7258 - accuracy: 0.7069\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7624 - accuracy: 0.4451\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7867 - accuracy: 0.6914\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.8027 - accuracy: 0.7103\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.8052 - accuracy: 0.7492\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7920 - accuracy: 0.7666\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.8041 - accuracy: 0.6963\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.8046 - accuracy: 0.4827\n",
      "Epoch 93/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7790 - accuracy: 0.5623\n",
      "Epoch 94/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7737 - accuracy: 0.7489\n",
      "Epoch 95/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7633 - accuracy: 0.7811\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7734 - accuracy: 0.7768A: 1s - loss: -0.\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7985 - accuracy: 0.7893\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.8139 - accuracy: 0.7923\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.7762 - accuracy: 0.7607\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 2s 8ms/step - loss: -0.8090 - accuracy: 0.7808\n"
     ]
    }
   ],
   "source": [
    "results = model_nn.fit(x_nn, y_nn, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.7746095061302185, 0.5589529275894165]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model_nn.evaluate(x_nn, y_nn, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_t = text.Tokenizer(num_words=7000)\n",
    "text_t.fit_on_texts((x_nn))\n",
    "list_tt = text_t.texts_to_sequences(x_nn)\n",
    "x_nn = sequence.pad_sequences(list_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn2.add(Embedding(7000, 15))\n",
    "model_nn2.add(Dense(10, activation='relu', kernel_regularizer=regularizers.l1(0.005)))\n",
    "model_nn2.add(LSTM(15))\n",
    "model_nn2.add(Dropout(0.5))\n",
    "model_nn2.add(Dense(3, activation='sigmoid'))\n",
    "model_nn2.add(Dropout(0.5))\n",
    "model_nn2.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, None, 15)          105000    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, None, 10)          160       \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 15)                1560      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 3)                 48        \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 106,772\n",
      "Trainable params: 106,772\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_nn2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model_nn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 11.5362 - accuracy: 0.3311 - val_loss: 11.4501 - val_accuracy: 0.3193\n",
      "Epoch 2/30\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 11.5185 - accuracy: 0.3311 - val_loss: 11.4329 - val_accuracy: 0.3193\n",
      "Epoch 3/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.5018 - accuracy: 0.3311 - val_loss: 11.4168 - val_accuracy: 0.3193\n",
      "Epoch 4/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.4862 - accuracy: 0.3311 - val_loss: 11.4017 - val_accuracy: 0.3193\n",
      "Epoch 5/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.4719 - accuracy: 0.3311 - val_loss: 11.3880 - val_accuracy: 0.3193\n",
      "Epoch 6/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.4585 - accuracy: 0.3311 - val_loss: 11.3750 - val_accuracy: 0.3193\n",
      "Epoch 7/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.4458 - accuracy: 0.3311 - val_loss: 11.3628 - val_accuracy: 0.3193\n",
      "Epoch 8/30\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 11.4341 - accuracy: 0.3311 - val_loss: 11.3517 - val_accuracy: 0.3193\n",
      "Epoch 9/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.4234 - accuracy: 0.3311 - val_loss: 11.3413 - val_accuracy: 0.3193\n",
      "Epoch 10/30\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 11.4132 - accuracy: 0.3311 - val_loss: 11.3315 - val_accuracy: 0.3193\n",
      "Epoch 11/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.4039 - accuracy: 0.3311 - val_loss: 11.3227 - val_accuracy: 0.3193\n",
      "Epoch 12/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.3956 - accuracy: 0.3311 - val_loss: 11.3149 - val_accuracy: 0.3193\n",
      "Epoch 13/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.3881 - accuracy: 0.3311 - val_loss: 11.3078 - val_accuracy: 0.3193\n",
      "Epoch 14/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.3815 - accuracy: 0.3311 - val_loss: 11.3017 - val_accuracy: 0.3193\n",
      "Epoch 15/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.3758 - accuracy: 0.3311 - val_loss: 11.2965 - val_accuracy: 0.3193\n",
      "Epoch 16/30\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 11.3712 - accuracy: 0.3311 - val_loss: 11.2924 - val_accuracy: 0.3193\n",
      "Epoch 17/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.3675 - accuracy: 0.3311 - val_loss: 11.2893 - val_accuracy: 0.3193\n",
      "Epoch 18/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.3650 - accuracy: 0.3311 - val_loss: 11.2874 - val_accuracy: 0.3193\n",
      "Epoch 19/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.3635 - accuracy: 0.3311 - val_loss: 11.2863 - val_accuracy: 0.3193\n",
      "Epoch 20/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.3629 - accuracy: 0.3311 - val_loss: 11.2861 - val_accuracy: 0.3193\n",
      "Epoch 21/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.3628 - accuracy: 0.3311 - val_loss: 11.2861 - val_accuracy: 0.3193\n",
      "Epoch 22/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.3628 - accuracy: 0.3311 - val_loss: 11.2861 - val_accuracy: 0.3193\n",
      "Epoch 23/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.3628 - accuracy: 0.3311 - val_loss: 11.2861 - val_accuracy: 0.3193\n",
      "Epoch 24/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.3628 - accuracy: 0.3311 - val_loss: 11.2861 - val_accuracy: 0.3193\n",
      "Epoch 25/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.3628 - accuracy: 0.3311 - val_loss: 11.2861 - val_accuracy: 0.3193\n",
      "Epoch 26/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.3628 - accuracy: 0.3311 - val_loss: 11.2861 - val_accuracy: 0.3193\n",
      "Epoch 27/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.3628 - accuracy: 0.3311 - val_loss: 11.2861 - val_accuracy: 0.3193\n",
      "Epoch 28/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.3628 - accuracy: 0.3311 - val_loss: 11.2861 - val_accuracy: 0.3193\n",
      "Epoch 29/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.3628 - accuracy: 0.3311 - val_loss: 11.2861 - val_accuracy: 0.3193\n",
      "Epoch 30/30\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 11.3628 - accuracy: 0.3311 - val_loss: 11.2861 - val_accuracy: 0.3193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13e0c8b11f0>"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nn2.fit(x_nn, y_nn, epochs=30, batch_size=256, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model gives us high accuracy but still struggles with negative tweets, let us try some hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_params = {'svc__C': [1,2,3,4,5],\n",
    "             'svc__kernel':['linear','rbf','sigmoid','poly'],\n",
    "              'svc__degree':[3,5,7,8],\n",
    "             }\n",
    "\n",
    "svc_gs = GridSearchCV(estimator=svc_pipe, param_grid=svc_params, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_results = svc_gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__C': 2, 'svc__degree': 3, 'svc__kernel': 'rbf'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch has determined these are our best parameters, so let's rerun the model with these to see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Score: 0.9565918834720761\n",
      "Mean Test Score: 0.6917429208899637\n"
     ]
    }
   ],
   "source": [
    "svc_pipe2 = Pipeline([(\"tfid\" , TfidfVectorizer(stop_words=sw.words('english'))),\n",
    "                     (\"svc\", SVC(C=2,kernel='rbf',degree=3))])\n",
    "results_svc = cross_validate(svc_pipe2,X_train,y_train,return_train_score=True)\n",
    "mean_scores(results_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.6917436574277753\n",
      "Precision Score: 0.6917436574277753\n",
      "Accuracy Score:0.6917436574277753\n",
      "F1 Score: 0.6917436574277753\n",
      "Confusion Matrix: \n",
      "[[1143 1123    7]\n",
      " [ 576 3488   44]\n",
      " [  79  273   86]]\n"
     ]
    }
   ],
   "source": [
    "y_svc2 = cross_val_predict(svc_pipe2,X_train,y_train)\n",
    "metrics(y_train,y_svc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model gives the highest accuracy and does the best job at classifying negative sentiments. We will choose this as our final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model - TFIDVectorizer with SVC Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7003959524857017"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_pipe2.fit(X_train,y_train)\n",
    "svc_pipe2.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a 70% accuracy on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(svc_pipe2,X_test,y_test,display_labels=['Positive','Neutral','Negative'],colorbar=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model needs improvement on finding negative sentiments. This would help if we had more negative tweets to go off of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Seperate Dataframes by company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apple = df.loc[df['company'] == 'apple']\n",
    "df_google = df.loc[df['company'] == 'google']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Chart displaying total sweets by sentiment for each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "\n",
    "ax1 = plt.subplot2grid(shape=(2,5), loc = (0,0))\n",
    "ax2 = plt.subplot2grid(shape=(2,5), loc = (0,1),)\n",
    "\n",
    "sns.barplot(x = df_apple['Emotion'].value_counts().index,\n",
    "           y = df_apple['Emotion'].value_counts().values,\n",
    "           ax =ax1)\n",
    "ax1.set_xticklabels(['Neutral', 'Positive', 'Negative'])\n",
    "ax1.set_title('Apple')\n",
    "ax1.set_ylim(0,3000)\n",
    "\n",
    "sns.barplot(x = df_google['Emotion'].value_counts().index,\n",
    "           y = df_google['Emotion'].value_counts().values,\n",
    "           ax = ax2)\n",
    "ax2.set_xticklabels(['Neutral', 'Positive', 'Negative'])\n",
    "ax2.set_title('Google')\n",
    "ax2.set_ylim(0,3000)\n",
    "ax2.set(yticklabels = []);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Chart showing distribution of tweet sentiment by category of item tweeted about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dict = {'iphone' : 'Phone/iPad', 'android': 'Phone/iPad', 'ipad': 'Phone/iPad', 'apple':'Platform',\n",
    "'google':'Platform', 'ipad or iphone app': 'App', 'android app': 'App', 'other google product or service' : 'Other product/service',\n",
    "'other apple product or service': 'Other product/service', 'ios': 'Other product/service', 'itunes': 'Other product/service'}\n",
    "df['category'] = df['test'].map(cat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,14))\n",
    "\n",
    "ax1 = plt.subplot2grid(shape=(2,4), loc=(0,0))\n",
    "ax2 = plt.subplot2grid(shape=(2,4), loc=(0,1))\n",
    "ax3 = plt.subplot2grid(shape=(2,4), loc=(1,0))\n",
    "ax4 = plt.subplot2grid(shape=(2,4), loc=(1,1))\n",
    "\n",
    "sns.barplot(x = df.loc[df.category == 'Phone/iPad']['target'].value_counts().index,\n",
    "               y = df.loc[df.category == 'Phone/iPad']['target'].value_counts(normalize=True),\n",
    "           ax=ax1)\n",
    "ax1.set_title('Phone/iPad')\n",
    "ax1.set_xlabel('Sentiment')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_xticklabels(['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "sns.barplot(x = df.loc[df.category == 'Platform']['target'].value_counts().index,\n",
    "            y = df.loc[df.category == 'Platform']['target'].value_counts(normalize=True),\n",
    "           ax=ax2)\n",
    "ax2.set_title('Platform')\n",
    "ax2.set_xlabel('Sentiment')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_xticklabels(['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "sns.barplot(x = df.loc[df.category == 'App']['target'].value_counts().index,\n",
    "               y = df.loc[df.category == 'App']['target'].value_counts(normalize=True),\n",
    "           ax=ax3)\n",
    "ax3.set_title('App-Related')\n",
    "ax3.set_xlabel('Sentiment')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.set_xticklabels(['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "sns.barplot(x = df.loc[df.category == 'Other product/service']['target'].value_counts().index,\n",
    "               y = df.loc[df.category == 'Other product/service']['target'].value_counts(normalize=True),\n",
    "           ax=ax4)\n",
    "ax4.set_title('Other Products/Services')\n",
    "ax4.set_xlabel('Sentiment')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.set_xticklabels(['Negative', 'Neutral', 'Positive']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfidf Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-02991fe49433>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mraw_neu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpos_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpos_tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_test' is not defined"
     ]
    }
   ],
   "source": [
    "raw_pos = []\n",
    "raw_neg = []\n",
    "raw_neu = []\n",
    "\n",
    "pos_tweets = df_test.loc[df.target==2]\n",
    "pos_tweets\n",
    "\n",
    "neg_tweets = df_test.loc[df.target==0]\n",
    "\n",
    "neutral_tweets = df_test.loc[df.target==1]\n",
    "\n",
    "for listx in pos_tweets.clean_tweet:\n",
    "    for x in listx:\n",
    "        raw_pos.append(x)\n",
    "    \n",
    "for listx in neg_tweets.clean_tweet:\n",
    "    for x in listx:\n",
    "        raw_neg.append(x)\n",
    "        \n",
    "for listx in neutral_tweets.clean_tweet:\n",
    "    for x in listx:\n",
    "        raw_neu.append(x)\n",
    "        \n",
    "raw_pos = ' '.join(raw_pos)\n",
    "raw_neg = ' '.join(raw_neg)\n",
    "raw_neu = ' '.join(raw_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_poswords = dict(df_topwords.loc[['positive']].max().sort_values(ascending=False)[:150])\n",
    "top_negwords = dict(df_topwords.loc[['negative']].max().sort_values(ascending=False)[:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
